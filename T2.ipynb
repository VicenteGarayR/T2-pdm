{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdIx0XW5kahb",
        "outputId": "d3fa715b-45ca-4d46-b71a-0098c12c991f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=7cb94f520c2eb2b987d8a2eef42494203b68dc71c077405b6a8c65faa125dc6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.20.0.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.4)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.20.0-py3-none-any.whl size=280771 sha256=25c6e6368d82b6e8425cd911e9a1fb116edfaf8994227a26319d4d220106bd79\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/12/66/764554d079caad4b9a11a02cfc0d200dd876d12935b9cf7e64\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.20.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install neo4j\n",
        "!pip install pandas\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "442cTyxfkahc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Ejemplo de PySpark en Jupyter Notebook\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Obtener el SparkContext\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CYSakHMFkahe"
      },
      "outputs": [],
      "source": [
        "#buckets\n",
        "B = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AwZLiuHTkahe"
      },
      "outputs": [],
      "source": [
        "def hash(x):\n",
        "    return x % B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ESduWr_1kahf"
      },
      "outputs": [],
      "source": [
        "# función para hacer map al grafo\n",
        "def map_pdm(x, arista, y):\n",
        "\n",
        "    x_hash = hash(x)\n",
        "    y_hash = hash(y)\n",
        "\n",
        "    l = []\n",
        "    for i in range(B):\n",
        "        l.append(((x_hash, y_hash, i), (x, arista, y)))\n",
        "        l.append(((i, x_hash, y_hash), (x, arista, y)))\n",
        "        l.append(((y_hash, i, x_hash), (x, arista, y)))\n",
        "\n",
        "    return set(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rywlAEcj2stk"
      },
      "outputs": [],
      "source": [
        "graph = [(1,11,2),(1,11,3),(2,11,3),(3,11,2),(3,11,4),(4,11,1),(4,11,2),(4,11,3),(4,12,5),(5,12,1),(5,12,2),(5,12,6)]\n",
        "#graph = [(2,11,2), (1,11,2), (2,11,1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTEw-ISE288F"
      },
      "source": [
        "Convertimos ``` graph ``` en un RDD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AYjf9CJ-kahf"
      },
      "outputs": [],
      "source": [
        "datos_rdd = sc.parallelize(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gVHRmXFY49J",
        "outputId": "ad389972-5036-4359-ec40-889f102b2b6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 11, 2), (1, 11, 3), (2, 11, 3), (3, 11, 2), (3, 11, 4)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos_rdd.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OadrVPqXk7W2"
      },
      "source": [
        "### Fase de Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkdCxpXr06Dt"
      },
      "source": [
        "Se ejecuta la función ``` map_pdm()``` obtenido los elementos de los iterables generados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O-XpnXMkahg",
        "outputId": "4f6591ff-89f7-43d0-c526-45f7aab43b8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((1, 0, 0), (1, 11, 2)), ((0, 1, 1), (1, 11, 2))]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_map = datos_rdd.flatMap(lambda dato: map_pdm(*dato))\n",
        "\n",
        "rdd_map.collect()[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHPcloZ1lCCq"
      },
      "source": [
        "### Reduce\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjpY6eoD30YF"
      },
      "source": [
        "Agrupamos los elementos de ``` rdd_map ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifArrQxelBRp",
        "outputId": "e348a7e8-2f01-4cbd-f77d-8acd1a6926e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 0, 0),\n",
              " [(1, 11, 2),\n",
              "  (2, 11, 3),\n",
              "  (3, 11, 2),\n",
              "  (3, 11, 4),\n",
              "  (4, 11, 1),\n",
              "  (4, 11, 2),\n",
              "  (4, 11, 3),\n",
              "  (4, 12, 5),\n",
              "  (5, 12, 2),\n",
              "  (5, 12, 6)])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_reduce = rdd_map.groupByKey().mapValues(list)\n",
        "rdd_reduce.collect()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fs5YcvBaoyFn"
      },
      "outputs": [],
      "source": [
        "#toma una lista de nodos y detecta todos los triángulos posibles en esa lista.\n",
        "def triangulo(nodos):\n",
        "  triangulos_detectados = []\n",
        "  for i in range(len(nodos)):\n",
        "    nodo_actual = nodos[i]\n",
        "\n",
        "    for j in range(i + 1, len(nodos)):\n",
        "\n",
        "      nodo_sig = nodos[j]\n",
        "\n",
        "      for k in range(j + 1, len(nodos)):\n",
        "        nodo_sub_sig = nodos[k]\n",
        "\n",
        "        if nodo_actual[2] == nodo_sig[0] and nodo_sig[2] == nodo_sub_sig[0] and nodo_actual[0] == nodo_sub_sig[2]:\n",
        "          triangulos_detectados.append((nodo_actual[0], nodo_sig[0], nodo_sub_sig[0]))\n",
        "\n",
        "        elif nodo_actual[2] == nodo_sub_sig[0] and nodo_sig[0] == nodo_sub_sig[2] and nodo_actual[0] == nodo_sig[2]:\n",
        "          triangulos_detectados.append((nodo_actual[0], nodo_sig[0], nodo_sub_sig[0]))\n",
        "\n",
        "        elif (nodo_actual[0] == nodo_sub_sig[0] and nodo_actual[2] == nodo_sig[2] and nodo_sub_sig[2] == nodo_sig[0]):\n",
        "          triangulos_detectados.append((nodo_actual[0], nodo_sig[0], nodo_sub_sig[0]))\n",
        "\n",
        "  return triangulos_detectados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkHzwXRZ1JR2",
        "outputId": "7cb8ca78-773b-4350-c636-a65ca5c82946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((1, 0, 0), [(2, 3, 4)]),\n",
              " ((0, 1, 0), [(2, 3, 4)]),\n",
              " ((0, 0, 1), [(2, 3, 4)]),\n",
              " ((1, 1, 1), []),\n",
              " ((0, 1, 1), [(1, 3, 4)]),\n",
              " ((1, 0, 1), [(1, 3, 4)]),\n",
              " ((1, 1, 0), [(1, 3, 4)]),\n",
              " ((0, 0, 0), [])]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aplicamos la función triangulo a cada elemento del RDD\n",
        "\n",
        "final = rdd_reduce.map(lambda nodos: (nodos[0], triangulo(nodos[1])))\n",
        "final.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sVOExZiG1wup"
      },
      "outputs": [],
      "source": [
        "dicc = {}\n",
        "for i in final.collect():\n",
        "    dicc[i[0]] = i[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtUNzf55KJq",
        "outputId": "f75788a5-1c52-4de1-de01-5dde928a1546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{(1, 0, 0): [(2, 3, 4)],\n",
              " (0, 1, 0): [(2, 3, 4)],\n",
              " (0, 0, 1): [(2, 3, 4)],\n",
              " (1, 1, 1): [],\n",
              " (0, 1, 1): [(1, 3, 4)],\n",
              " (1, 0, 1): [(1, 3, 4)],\n",
              " (1, 1, 0): [(1, 3, 4)],\n",
              " (0, 0, 0): []}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dicc"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
